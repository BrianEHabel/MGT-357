# Practitioner Evidence: Methods & Acquisition Strategy
# Document your approach to gathering expert insights and professional experience

## Practitioner Evidence Goals
**Primary Goal:** To gather practitioner insights about psychological safety problems (X) and how they manifest in real organizational team settings, particularly in engineering and tech environments.
**Secondary Goal:** To understand practitioner perspectives on how psychological safety impacts decision-quality outcomes (Y) and what interventions practitioners have found effective.

## Target Practitioners

### Industry Experts
**Target Profile:** Practitioners with direct experience in team communication, leadership, and decision-making in engineering and tech contexts.
- Years of experience desired: 5-15+ years
- Industry/sector focus: Technology, engineering, cloud services, cross-functional project teams
- Role/position types: Engineering team leads, Scrum Masters, organizational psychologists, senior consultants, program managers
- Company size experience: Mid-size tech companies to large enterprises
- Geographic location: Not restricted - prioritizing quality of experience over location

### Specific Practitioners Identified
1. **Engineering Team Lead / Mid-size Tech Company**
   - **Relevance:** 8 years of direct experience managing engineering teams, firsthand exposure to team communication dynamics and decision-making challenges
   - **Contact Method:** LinkedIn message, followed by informal conversation

2. **Scrum Master / Cloud Services Firm**
   - **Relevance:** 5 years of experience facilitating team processes, observing psychological safety issues and their impact on sprint outcomes
   - **Contact Method:** In-person conversation

3. **Published Practitioners via HBR, McKinsey, Deloitte, Google Re:Work**
   - **Relevance:** Senior leaders and organizational psychologists who have documented real-world lessons on psychological safety and team performance
   - **Contact Method:** Published articles and practitioner reports

## Acquisition Methods

### Expert Interviews
#### Interview Planning
- **Target Number:** 2 informal practitioner conversations completed
- **Interview Length:** Approximately 30-45 minutes each
- **Interview Method:** One LinkedIn message exchange, one in-person conversation
- **Recording Plan:** Documented detailed notes immediately after conversations

#### Interview Protocol
**Opening Questions:**
- Can you tell me about your experience managing/facilitating engineering teams?
- How long have you been working in this field/role?

**Problem-Focused Questions:**
- Have you encountered situations where team members were hesitant to voice dissenting opinions?
- What causes teams to fall into groupthink in your experience?
- How common is the problem of insufficient challenge and debate in technical decision-making?
- What patterns have you noticed around psychological safety in your teams?

**Solution-Focused Questions:**
- What approaches have you seen work for encouraging healthy dissent?
- What interventions have you tried to improve team communication and decision quality?
- What would you recommend based on your experience for teams struggling with groupthink?

**Implementation Questions:**
- What challenges should we expect when trying to build psychological safety?
- What would you do differently if you were addressing this problem again?
- What resources or support are critical for success in improving team communication?

**Closing Questions:**
- Who else would you recommend I speak with about this?
- Is there anything important I haven't asked about?

### Professional Networks

#### LinkedIn Outreach
- **Target Search Terms:** "engineering team lead," "scrum master," "agile coach," "organizational psychologist," "tech team manager"
- **Connection Strategy:** Direct messages to practitioners with relevant experience, explaining academic research purpose
- **Message Template:** "Hi [Name], I'm conducting research on psychological safety and team decision-making in engineering contexts. Would you be willing to share brief insights from your experience? This is for academic purposes [context]. Thank you for considering."

#### Industry Associations
- **Relevant Associations:** Scrum Alliance, Project Management Institute, local tech leadership groups
- **Contact Strategy:** Leveraging existing connections and LinkedIn for informal conversations
- **Events/Forums:** Tech meetups and leadership forums (as opportunities arise)

### Case Study Research

#### Published Case Studies
- **Target Sources:** 
  - Harvard Business Review (HBR) practitioner articles
  - McKinsey & Company reports on team performance
  - Deloitte Insights on organizational behavior
  - Google Re:Work (Project Aristotle research summaries)
- **Search Strategy:** 
  - Keyword combinations: "psychological safety," "team dissent," "decision failures," "groupthink," "engineering team performance," "management mistakes"
  - Used AI tools (ChatGPT) to generate additional search terms and summarize articles for faster synthesis
  - All interpretations manually verified
- **Documentation Plan:** Summarized key practitioner insights with source citations in evidence synthesis document

#### Company Examples
- **Target Companies:** Google (Project Aristotle), organizations featured in HBR/McKinsey case studies
- **Information Sources:** Published practitioner guides, internal research summaries made public, consulting reports
- **Contact Strategy:** Relied on published materials rather than direct company outreach

## Documentation Strategy

### Interview Documentation
- **Recording:** No audio/video recording (informal conversations)
- **Note-taking:** Detailed notes documented immediately after conversations
- **Transcription:** Notes-based summaries of key insights
- **Analysis:** Coded responses for themes related to (X) psychological safety problems and (Y) decision quality outcomes

### Case Study Documentation
- **Template:** Standardized summary format capturing:
  - Source and author credentials
  - Key practitioner insights on problem (X)
  - Key practitioner insights on outcomes (Y)
  - Interventions recommended or tested
  - Relevance to research question
- **Key Elements:** Problem manifestation, causal factors, solution effectiveness, implementation lessons
- **Source Tracking:** Full citations maintained for all HBR, McKinsey, Deloitte, Google sources

## Outreach Strategy

### Contact Approach
**Initial Contact Message Template:**
"Hi [Name], I'm a graduate student researching how psychological safety influences decision quality in engineering teams. I noticed your experience with [specific context]. Would you be open to a brief informal conversation about your observations? This is for academic research purposes. I'd be happy to share findings when complete. Thank you for considering."

**Follow-up Strategy:**
One follow-up message if no response within 1 week. No additional follow-ups to respect practitioners' time.

**Incentives:**
- Offer to share research findings summary
- Professional networking opportunity
- Acknowledgment of their contribution (with permission)

### Timing Plan
- **Outreach Start Date:** Early in research process (before evidence synthesis)
- **Interview Window:** 2-3 weeks for conducting informal conversations
- **Follow-up Period:** Allowed 1 week for clarifying questions if needed

## Ethical Considerations

### Informed Consent
- **Purpose Explanation:** Clearly stated academic research purpose at outset of all conversations
- **Use of Information:** Explained that insights would be synthesized into evidence-based management research
- **Anonymity/Attribution:** Practitioners kept anonymous (no names or identifying company details in final documentation)
- **Approval Process:** Informal conversations for general insights only; no formal approval process required

### Professional Courtesy
- **Time Respect:** Kept conversations within 30-45 minutes; respected busy schedules
- **Preparation:** Prepared focused questions in advance
- **Follow-through:** Offered to share research summary when complete

## Expected Challenges

### Access Challenges
Limited network of senior practitioners; relied on LinkedIn connections and published sources to supplement direct conversations.

### Response Rate Concerns
Expected low response rate for cold LinkedIn outreach; prioritized published practitioner sources (HBR, McKinsey, Google) as primary evidence base with informal conversations as supplementary validation.

### Quality Concerns
Focused on credible publication platforms and practitioners with substantial relevant experience. Cross-referenced practitioner insights with academic literature.

### Time Constraints
Limited time for extensive interview processes; used combination of published practitioner analyses and targeted informal conversations.

## Backup Plans

### Alternative Sources
Primary reliance on published practitioner articles from credible sources (HBR, McKinsey, Deloitte, Google Re:Work) ensures robust practitioner evidence even with limited direct interviews.

### Modified Approaches
If direct practitioner access remained limited, increased depth of published case study analysis and practitioner report synthesis.

### Minimum Viable Evidence
At minimum: 3-5 high-quality published practitioner sources plus 1-2 informal practitioner conversations to validate real-world relevance.

---

## ACTUAL PRACTITIONER SOURCES CONSULTED

### Published Practitioner Sources
1. **Harvard Business Review (HBR)** - Practitioner articles by senior leaders and organizational psychologists
2. **Google Re:Work** - Project Aristotle research summaries from engineering team leads and program managers
3. **McKinsey & Company** - Practitioner reports on team performance, psychological safety, and decision failures
4. **Deloitte Insights** - Articles by consultants specializing in organizational behavior and team culture

### Direct Practitioner Conversations
1. **Engineering Team Lead** - Mid-size tech company, 8 years experience
2. **Scrum Master** - Cloud services firm, 5 years experience

### Selection Criteria Applied
Practitioners selected based on:
- Direct experience with team communication, leadership, and decision-making
- Experience in engineering, tech, or cross-functional project teams
- Published practitioner analyses reflecting real-world lessons, not only academic findings
- Credibility of publication platforms (HBR, McKinsey, Deloitte, Google Re:Work)

### Evidence Acquisition Methods Used
- Searched HBR and McKinsey using keywords: "psychological safety," "team dissent," "decision failures," "groupthink," "engineering team performance," "management mistakes"
- Reviewed Google Re:Work's practitioner guides on building psychological safety
- Conducted informal practitioner conversations via LinkedIn messages and in-person
- Documented notes immediately after conversations
- Used AI tools (ChatGPT) to generate search terms and summarize practitioner articles; all interpretations manually verified

### Relevance to Research Question
Practitioner evidence directly addresses:
- How psychological safety (X) shapes team communication norms
- Why fear of social friction causes groupthink in engineering contexts
- How lack of dissent and challenge worsens decision quality (Y)
- Which interventions practitioners find most effective (e.g., structured dissent roles, anonymous input tools, pre-mortems)

These practitioner insights validate both the nature of the problem (X) and the likely effectiveness of proposed interventions (Y → better decisions).

---
COMPLETION NOTES:
- Practitioner evidence gathering completed with mix of published sources and direct conversations
- Published practitioner sources provide robust foundation of real-world insights
- Direct conversations validate and supplement published findings
- Evidence acquisition methods documented for transparency and replicability

# Practitioner Evidence: Collection Methods

## Evidence Collection Approach

**Source Types:**
1. Industry research reports (Google, McKinsey)
2. Academic-practitioner publications (Harvard Business Review)
3. Direct practitioner interviews (Engineering Team Lead, Scrum Master)

**Collection Period:** Throughout Milestone 2 research phase (ongoing)

## Google Project Aristotle (2016)

**Research Method:**
Internal longitudinal study combining quantitative and qualitative data

**Data Collection:**
- Team effectiveness surveys (180 engineering teams)
- Performance metrics (objective outcomes)
- Qualitative interviews with team members and managers
- 2-year observation period

**Analysis Approach:**
- Statistical modeling to identify predictors of team effectiveness
- Comparative analysis of high vs. low performing teams
- Factor analysis to isolate key variables

**Credibility Factors:**
✓ Transparent methodology (published on Google re:Work)
✓ Large sample (180 teams)
✓ Rigorous internal research standards
✓ Results validated by external researchers

## McKinsey & Company (2019)

**Research Method:**
Multi-client survey and case study analysis

**Data Collection:**
- Executive surveys across Fortune 500 organizations
- Client engagement data from consulting projects
- Retrospective analysis of decision outcomes
- Financial impact tracking

**Analysis Approach:**
- Cross-company comparative analysis
- Decision quality assessment frameworks
- ROI calculations for interventions
- Before/after comparison studies

**Credibility Factors:**
✓ Multi-client data (not single organization)
✓ Rigorous analytical frameworks
✓ Cross-industry validation
✓ Quantified outcomes (19% improvement, 24% reduction)

## HBR - Amy Edmondson

**Research Method:**
Synthesis of 20+ years of field research and case studies

**Data Sources:**
- Edmondson's own empirical studies (published in top journals)
- Case study organizations implementing psychological safety interventions
- Practitioner feedback and implementation experiences

**Analysis Approach:**
- Theory-to-practice translation
- Pattern identification across multiple contexts
- Best practice extraction from successful implementations

**Credibility Factors:**
✓ Preeminent researcher in field (20+ years expertise)
✓ Academic rigor meets practical application
✓ Extensive case study validation
✓ Framework tested across industries

## Direct Practitioner Interviews

**Interview Method:**
Semi-structured conversations with practicing managers/facilitators

**Interview Protocol:**
1. Problem Recognition: "What psychological safety issues do you observe?"
2. Intervention Experience: "What interventions have you tried?"
3. Effectiveness Assessment: "What worked? What didn't?"
4. Implementation Lessons: "What advice would you give?"

**Participants:**
- Engineering Team Lead (8 years experience, mid-size tech)
- Scrum Master (5 years experience, cloud services)

**Data Recording:**
- Detailed notes taken during conversations
- Key quotes documented
- Themes extracted across interviews

**Analysis Approach:**
- Thematic analysis of common patterns
- Triangulation with published research
- Identification of engineering-specific concerns

**Limitations Acknowledged:**
⚠ Small sample size (N=2 practitioners)
⚠ Single organization per practitioner
⚠ Retrospective self-report (potential recall bias)
⚠ Not formally recorded/transcribed

**Mitigations:**
✓ Used to validate (not establish) findings from larger studies
✓ Triangulated with Google/McKinsey research
✓ Focused on concrete examples and specific tools
